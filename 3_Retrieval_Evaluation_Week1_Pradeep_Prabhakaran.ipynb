{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7d49f27a-15ba-4176-bf6d-211051a8cef6",
      "metadata": {
        "id": "7d49f27a-15ba-4176-bf6d-211051a8cef6"
      },
      "source": [
        "#### Week 1: Vector Search Applications w/ LLMs.  Authored by Chris Sanchez."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8a48d4e-11e4-45b5-8cfc-f595d61e11bd",
      "metadata": {
        "id": "b8a48d4e-11e4-45b5-8cfc-f595d61e11bd"
      },
      "source": [
        "# Week 1 - Notebook 3\n",
        "\n",
        "# Overview\n",
        "***\n",
        "Welcome to the final notebook for Week 1! Take a look at all the ground we've covered so far:\n",
        "- Chunking/splitting\n",
        "- Vectorization of text\n",
        "- Combining with metadata\n",
        "- Saving to disk\n",
        "- Class Configuration\n",
        "- Data Indexing\n",
        "- Keyword search\n",
        "- Vector search\n",
        "- OPTIONAL: Searching with Filters\n",
        "\n",
        "We are now prepared to move on to a very important topic, **Retrieval Evaluation**.  I hope you've noticed that the search results will differ (sometimes slightly, sometimes by a lot) depeding on which search method you used: `keyword_search` or `vector_search`.  As humans, it's fairly easy for us to determine whether the returned search results are relevant to the query that was submitted, (though even here there will be differing opinions on result relevance).  But how do we systematically determine which search method is better in general?  And how do we measure the relative performance of our retrieval system if we change one of it's parameters...for example, changing our embedding model? What about measuring system performance over time as more documents are added to our datastore?\n",
        "\n",
        "We need a way to evaluate our retrieval system, and this notebook will show you \"one way\" of doing that.  I say \"one way\" because there are many ways to approach this problem, and the method I'm showing you is not perfect (if anything it's a bit too conservative).  Ultimately, measuring retrieval performance is hard because it requires a lot of time and effort, and absent any user [click-data](https://en.wikipedia.org/wiki/Click_tracking), requires some form of data labeling.  With the advent of powerful generative LLMs the process of measuring retrieval performance has become much easier. Let's take a look at how that works.\n",
        "\n",
        "# Retrieval Evaluation - Process\n",
        "***\n",
        "Here's a high-level overview of how the Retrieval Evaluation process in this notebook works:\n",
        "\n",
        "1. Generate a \"golden dataset\" of query-context pairs.  I used a pseudo-LlamaIndex implementation for this step.  I say \"pseudo\" implementation because I used LlamaIndex as the backbone, but I had to rewrite significant portions of the dataset generation code because of the opinionated way that LlamaIndex is built. 100 document chunks (contexts) were randomly selected from the Impact Theory corpus and those chunks were then submitted to the `gpt-3.5-turbo` model which generated a query that could be answered by the context.  The output was 100 query-context pairs along with associated doc_ids.\n",
        "   - **Assumptions**:\n",
        "     - The generated query-context pairs are, in fact, relevant to one another i.e. the query can be answered by the context that it's paired with\n",
        "     - The generated queries are simliar in style and length to the type of queries that end users would ask\n",
        "2. The golden dataset consists of three primary keys: `corpus`, `relevant_docs`, and `queries`\n",
        "     - The `corpus` is the original text context/chunk with it's associated `doc_id`\n",
        "     - The `queries` are the LLM generated queries, one (or more) for each entry in the `corpus`\n",
        "     - The `relevant_docs` is a simple lookup table linking the `corpus` docs to the generated `queries`\n",
        "3. We pass the golden dataset into a retrieval evluation function which does the following:\n",
        "   - Takes in a `retriever` arg (`WeaviateClient`) and a few other configuration params\n",
        "   - Iterates over all queries in the golden dataset and retrieves search results for each query from Weaviate datastore\n",
        "   - Extracts all `doc_id` values from the retrieved results\n",
        "   - Extracts the `doc_id` from the associated `relevant_docs` for each query\n",
        "   - Checks if the relevant doc_id is in the list of retrieved result doc_ids\n",
        "   - After all queries are completed a `hit_rate` score and `mrr` score are calculated for the entire golden dataset\n",
        "   - Writes results to an `eval_results` folder\n",
        "\n",
        "#### In a Nutshell\n",
        "Ulitmately, given a golden dataset consisting of queries, relevant docs, and their associated doc_ids, the `retrieval_evaluation` function is checking if the relevant doc_id is found in the list of retrieved results doc_ids, for each query.\n",
        "\n",
        "#### Problems with this Approach\n",
        "The problems with this approach are many, I'll cover a few here:\n",
        "- The **Assumptions** (see section 1 above) about the golden dataset must hold true.  Given that the pairs are generated by `gpt-3.5-turbo`, I think the first assumption will generally be true.  When reviewing the dataset I did find a few questions that were not answerable given the context, but for the most part they were.  The 2nd assumption though, is going to be dependent on your particular search use case.  I think for the purposes of this course, the questions generated are a decent reflection of how someone would query this dataset, and therefore do the job of measuring retriever performance.  But I would always check a real-world query distribution before using an approach like the one presented here.\n",
        "- This approach is conversative in that there is only \"one\" right answer.  Either the relevant `doc_id` is in the results list or it isn't.  In reality, there are going to be several documents that could potentially answer the generated query, but we have no way to account for these other relevant documents, unless of course, we want to manually add doc_ids to the golden dataset (and depending on your business case, you may actually want to do that).\n",
        "- We aren't measuring recall or precision because we aren't classifying other documents as \"negatives\".  As was just mentioned, the other documents in the results list may or may not be good matches, we just don't know.  Because we don't know, we can't really classify the other documents as \"negatives\".  So for this approach, we are measuring the [\"hit rate\"](https://uplimit.com/course/vector-search-apps/admin2/content/session_cln9hzpkl00721aah4hbz06fc/module/module_clo3hmyh0006p12cb3bmygky4) which is simply a count of the number of times that we found a relevant `doc_id` match in the results list and [Mean Reciprocal Rank (MRR)](https://uplimit.com/course/vector-search-apps/admin2/content/session_cln9hzpkl00721aah4hbz06fc/module/module_clo3hmyh0006p12cb3bmygky4).  We're using MRR over other metrics such as Mean Average Precision (MAP) because we are only looking at a [single relevant answer](https://stats.stackexchange.com/questions/127041/mean-average-precision-vs-mean-reciprocal-rank).  Hit rate is a good enough metric for determining if our retriever is retrieving quality results, and MRR will become more important later on when we add a Reranker to the mix.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Check if file already exists\n",
        "if os.path.exists('.env'):\n",
        "    os.remove('.env')\n",
        "\n",
        "# Upload file\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Rename file\n",
        "try:\n",
        "    os.rename(file_name, '.env')\n",
        "    print('File uploaded and renamed successfully.')\n",
        "except:\n",
        "    print('Error renaming file.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "WpWBDe7cPyDf",
        "outputId": "d1d74b1f-f71d-4c4a-b396-8747caed56c5"
      },
      "id": "WpWBDe7cPyDf",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1b7f3bcb-3a9b-422c-a26b-3a0116ef0de8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1b7f3bcb-3a9b-422c-a26b-3a0116ef0de8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving env.txt to env.txt\n",
            "File uploaded and renamed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Github/vectorsearch-applications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVioYvOlP-ip",
        "outputId": "1eb0c990-1273-427a-fcec-5e361a813063"
      },
      "id": "tVioYvOlP-ip",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Github/vectorsearch-applications\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install requirements\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbx6wOpuQT9d",
        "outputId": "63d0089b-06f5-43ae-a741-4d95872c3d3a"
      },
      "id": "bbx6wOpuQT9d",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4==4.12.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: datasets==2.14.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.14.3)\n",
            "Requirement already satisfied: huggingface-hub==0.16.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.16.4)\n",
            "Requirement already satisfied: ipython==8.14.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (8.14.0)\n",
            "Requirement already satisfied: ipywidgets==8.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (8.1.1)\n",
            "Requirement already satisfied: jedi==0.19.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.19.0)\n",
            "Requirement already satisfied: jupyter-events==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: jupyter-lsp==2.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: jupyter_client==8.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.3.0)\n",
            "Requirement already satisfied: jupyter_core==5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.3.1)\n",
            "Requirement already satisfied: jupyter_server==2.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.7.0)\n",
            "Requirement already satisfied: jupyter_server_terminals==0.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.4.4)\n",
            "Requirement already satisfied: jupyterlab==4.0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments==0.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.2.2)\n",
            "Requirement already satisfied: jupyterlab-widgets==3.0.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.0.9)\n",
            "Requirement already satisfied: jupyterlab_server==2.24.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.24.0)\n",
            "Requirement already satisfied: langchain==0.0.310 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.0.310)\n",
            "Requirement already satisfied: langcodes==3.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (3.3.0)\n",
            "Requirement already satisfied: langsmith==0.0.43 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (0.0.43)\n",
            "Requirement already satisfied: llama-hub==0.0.47post1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (0.0.47.post1)\n",
            "Requirement already satisfied: llama-index==0.9.6.post1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (0.9.6.post1)\n",
            "Requirement already satisfied: loguru==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.7.0)\n",
            "Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (3.7.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (0.1.6)\n",
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (1.24.4)\n",
            "Requirement already satisfied: openai==1.3.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (1.3.5)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.0.3)\n",
            "Requirement already satisfied: protobuf==4.23.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (4.23.4)\n",
            "Requirement already satisfied: pyarrow==12.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (12.0.1)\n",
            "Requirement already satisfied: python-dotenv==1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (1.0.0)\n",
            "Requirement already satisfied: rank-bm25==0.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.2.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (1.3.1)\n",
            "Requirement already satisfied: rich==13.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (13.7.0)\n",
            "Requirement already satisfied: sentence-transformers==2.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (2.2.2)\n",
            "Requirement already satisfied: streamlit==1.28.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (1.28.2)\n",
            "Requirement already satisfied: tiktoken==0.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (0.5.1)\n",
            "Requirement already satisfied: tokenizers==0.13.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (0.13.3)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (2.0.1)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (4.66.1)\n",
            "Requirement already satisfied: transformers==4.33.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (4.33.1)\n",
            "Requirement already satisfied: weaviate-client==3.25.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (3.25.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.12.2->-r requirements.txt (line 1)) (2.5)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.3->-r requirements.txt (line 2)) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.3->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.3->-r requirements.txt (line 2)) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.3->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.3->-r requirements.txt (line 2)) (3.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.3->-r requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.3->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.16.4->-r requirements.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.16.4->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==8.14.0->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==8.14.0->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==8.14.0->-r requirements.txt (line 4)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython==8.14.0->-r requirements.txt (line 4)) (3.0.41)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython==8.14.0->-r requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython==8.14.0->-r requirements.txt (line 4)) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/dist-packages (from ipython==8.14.0->-r requirements.txt (line 4)) (5.7.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==8.14.0->-r requirements.txt (line 4)) (4.9.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.1->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.1->-r requirements.txt (line 5)) (4.0.9)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi==0.19.0->-r requirements.txt (line 6)) (0.8.3)\n",
            "Requirement already satisfied: jsonschema[format-nongpl]>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-events==0.7.0->-r requirements.txt (line 7)) (4.19.2)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events==0.7.0->-r requirements.txt (line 7)) (2.0.7)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from jupyter-events==0.7.0->-r requirements.txt (line 7)) (0.31.1)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events==0.7.0->-r requirements.txt (line 7)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events==0.7.0->-r requirements.txt (line 7)) (0.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter_client==8.3.0->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_client==8.3.0->-r requirements.txt (line 9)) (25.1.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from jupyter_client==8.3.0->-r requirements.txt (line 9)) (6.3.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter_core==5.3.1->-r requirements.txt (line 10)) (4.0.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (23.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (5.9.2)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (7.4.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (0.19.0)\n",
            "Requirement already satisfied: send2trash in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (0.18.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter_server==2.7.0->-r requirements.txt (line 11)) (1.6.4)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab==4.0.4->-r requirements.txt (line 13)) (2.0.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyterlab==4.0.4->-r requirements.txt (line 13)) (5.5.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab==4.0.4->-r requirements.txt (line 13)) (0.2.3)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from jupyterlab==4.0.4->-r requirements.txt (line 13)) (2.0.1)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab_server==2.24.0->-r requirements.txt (line 16)) (2.13.1)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab_server==2.24.0->-r requirements.txt (line 16)) (0.9.14)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.310->-r requirements.txt (line 17)) (2.0.23)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.310->-r requirements.txt (line 17)) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.310->-r requirements.txt (line 17)) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.310->-r requirements.txt (line 17)) (1.33)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.310->-r requirements.txt (line 17)) (1.10.13)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.310->-r requirements.txt (line 17)) (8.2.3)\n",
            "Requirement already satisfied: html2text in /usr/local/lib/python3.10/dist-packages (from llama-hub==0.0.47post1->-r requirements.txt (line 20)) (2020.1.16)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from llama-hub==0.0.47post1->-r requirements.txt (line 20)) (5.9.5)\n",
            "Requirement already satisfied: pyaml<24.0.0,>=23.9.7 in /usr/local/lib/python3.10/dist-packages (from llama-hub==0.0.47post1->-r requirements.txt (line 20)) (23.9.7)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from llama-hub==0.0.47post1->-r requirements.txt (line 20)) (1.3.4)\n",
            "Requirement already satisfied: aiostream<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.6.post1->-r requirements.txt (line 21)) (0.5.2)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.6.post1->-r requirements.txt (line 21)) (1.2.14)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.6.post1->-r requirements.txt (line 21)) (0.25.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.6.post1->-r requirements.txt (line 21)) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.6.post1->-r requirements.txt (line 21)) (3.8.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.6.post1->-r requirements.txt (line 21)) (0.9.0)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.6.post1->-r requirements.txt (line 21)) (1.26.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->-r requirements.txt (line 23)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->-r requirements.txt (line 23)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->-r requirements.txt (line 23)) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->-r requirements.txt (line 23)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->-r requirements.txt (line 23)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->-r requirements.txt (line 23)) (3.0.9)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.3.5->-r requirements.txt (line 26)) (1.7.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->-r requirements.txt (line 27)) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->-r requirements.txt (line 27)) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 32)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 32)) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 32)) (2023.11.17)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib==1.3.1->-r requirements.txt (line 33)) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.0->-r requirements.txt (line 34)) (3.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 35)) (0.15.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 35)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 35)) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 35)) (0.1.99)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (6.8.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (0.8.1b0)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.28.2->-r requirements.txt (line 36)) (3.0.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1->-r requirements.txt (line 37)) (2023.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 39)) (2.0.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.1->-r requirements.txt (line 41)) (0.4.1)\n",
            "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from weaviate-client==3.25.3->-r requirements.txt (line 42)) (1.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 39)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 39)) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 39)) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 39)) (17.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 2)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 2)) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit==1.28.2->-r requirements.txt (line 36)) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit==1.28.2->-r requirements.txt (line 36)) (0.12.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter_server==2.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter_server==2.7.0->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: cryptography>=3.2 in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client==3.25.3->-r requirements.txt (line 42)) (41.0.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.310->-r requirements.txt (line 17)) (3.20.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index==0.9.6.post1->-r requirements.txt (line 21)) (1.14.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.28.2->-r requirements.txt (line 36)) (4.0.11)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index==0.9.6.post1->-r requirements.txt (line 21)) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index==0.9.6.post1->-r requirements.txt (line 21)) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit==1.28.2->-r requirements.txt (line 36)) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->jupyter_server==2.7.0->-r requirements.txt (line 11)) (2.1.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.310->-r requirements.txt (line 17)) (2.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events==0.7.0->-r requirements.txt (line 7)) (2023.11.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events==0.7.0->-r requirements.txt (line 7)) (0.13.2)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events==0.7.0->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events==0.7.0->-r requirements.txt (line 7)) (20.11.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events==0.7.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events==0.7.0->-r requirements.txt (line 7)) (1.13)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.0->-r requirements.txt (line 34)) (0.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter_server==2.7.0->-r requirements.txt (line 11)) (4.9.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter_server==2.7.0->-r requirements.txt (line 11)) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter_server==2.7.0->-r requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter_server==2.7.0->-r requirements.txt (line 11)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter_server==2.7.0->-r requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter_server==2.7.0->-r requirements.txt (line 11)) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter_server==2.7.0->-r requirements.txt (line 11)) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter_server==2.7.0->-r requirements.txt (line 11)) (2.19.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.6.post1->-r requirements.txt (line 21)) (1.3.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==8.14.0->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.14.0->-r requirements.txt (line 4)) (0.2.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter_client==8.3.0->-r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.310->-r requirements.txt (line 17)) (3.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index==0.9.6.post1->-r requirements.txt (line 21)) (1.0.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter_server==2.7.0->-r requirements.txt (line 11)) (21.2.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyterlab==4.0.4->-r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2->-r requirements.txt (line 35)) (3.2.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython==8.14.0->-r requirements.txt (line 4)) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython==8.14.0->-r requirements.txt (line 4)) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython==8.14.0->-r requirements.txt (line 4)) (0.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->-r requirements.txt (line 39)) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client==3.25.3->-r requirements.txt (line 42)) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.28.2->-r requirements.txt (line 36)) (5.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter_server==2.7.0->-r requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events==0.7.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events==0.7.0->-r requirements.txt (line 7)) (2.8.19.14)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client==3.25.3->-r requirements.txt (line 42)) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aa6a6f95-91c6-4a08-a3a0-2aafc2d56b77",
      "metadata": {
        "id": "aa6a6f95-91c6-4a08-a3a0-2aafc2d56b77"
      },
      "outputs": [],
      "source": [
        "#standard library imports\n",
        "from typing import List, Tuple, Dict, Any\n",
        "import time\n",
        "import os\n",
        "\n",
        "# utilities\n",
        "from tqdm.notebook import tqdm\n",
        "from rich import print\n",
        "from dotenv import load_dotenv\n",
        "env = load_dotenv('./.env', override=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init vectorsearch-applications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSt9TLTQTjth",
        "outputId": "bc7048a8-4ae5-4df2-8c35-38dcf1dcdd21"
      },
      "id": "GSt9TLTQTjth",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/drive/MyDrive/Github/vectorsearch-applications/vectorsearch-applications/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e4522b4-5248-4936-af87-b0a2220bdb6d",
      "metadata": {
        "id": "5e4522b4-5248-4936-af87-b0a2220bdb6d"
      },
      "source": [
        "# Assignment 1.3\n",
        "***\n",
        "#### Instructions:\n",
        "* Import the `golden_100.json` dataset using the `from_json` method of the LlamaIndex `EmbeddingQAFinetuneDataset` Class\n",
        "  - **side note: The `EmbeddingQAFinetuneDataset` Class is the same class used for creating fine-tuning datasets\n",
        "* Instantiate a new Weaviate Client (Retriever) and set the `class_name` of the Class that you created in Notebook 2\n",
        "* Evaluate your retriever results using the `retrieval_evaluation` function\n",
        "* Submit your results in the form of a text file to Uplimit (the function autogenerates a report in the `dir_outpath` directory)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c9968b62-3814-40b9-bb2a-8c76968825c0",
      "metadata": {
        "id": "c9968b62-3814-40b9-bb2a-8c76968825c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3d517105-724e-49a7-dcbf-42af5c489602"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Num queries in Golden Dataset: \u001b[1;36m100\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Num queries in Golden Dataset: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from retrieval_evaluation import calc_hit_rate_scores, calc_mrr_scores, record_results, add_params\n",
        "from llama_index.finetuning import EmbeddingQAFinetuneDataset\n",
        "from weaviate_interface import WeaviateClient\n",
        "\n",
        "#################\n",
        "##  START CODE ##\n",
        "#################\n",
        "\n",
        "# Load QA dataset\n",
        "golden_dataset = EmbeddingQAFinetuneDataset.from_json(\"/content/drive/MyDrive/Github/vectorsearch-applications/data/golden_100.json\")\n",
        "\n",
        "# should see 100 queries\n",
        "print(f'Num queries in Golden Dataset: {len(golden_dataset.queries)}')\n",
        "\n",
        "### Instantiate Weaviate client and set Class name\n",
        "# read env vars from local .env file\n",
        "\n",
        "api_key = os.environ['WEAVIATE_API_KEY']\n",
        "url = os.environ['WEAVIATE_ENDPOINT']\n",
        "\n",
        "client = WeaviateClient(api_key, url)\n",
        "class_name = 'Impact_theory_minilm_256'\n",
        "\n",
        "#check if WCS instance is live and ready\n",
        "client.is_live(), client.is_ready()\n",
        "#################\n",
        "##  END CODE   ##\n",
        "#################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dbc77d4-07d3-4e3f-8330-76aefea948c6",
      "metadata": {
        "id": "2dbc77d4-07d3-4e3f-8330-76aefea948c6"
      },
      "source": [
        "#### Once your golden dataset is loaded in memory, you can view its content using dot notation like so: `golden_dataset.queries`, `golden_dataset.corpus`, `golden_dataset.relevant_docs`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "golden_dataset.corpus"
      ],
      "metadata": {
        "id": "_5ovR6zZXfNq"
      },
      "id": "_5ovR6zZXfNq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "946e13a3-9350-40d9-8bfe-0cd37f2ade2f",
      "metadata": {
        "id": "946e13a3-9350-40d9-8bfe-0cd37f2ade2f"
      },
      "source": [
        "# Project 1: Retrieval Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "255bdabd-770e-4b12-8bd8-54e5cdc64f77",
      "metadata": {
        "id": "255bdabd-770e-4b12-8bd8-54e5cdc64f77"
      },
      "outputs": [],
      "source": [
        "def retrieval_evaluation(dataset: EmbeddingQAFinetuneDataset,\n",
        "                         class_name: str,\n",
        "                         retriever: WeaviateClient,\n",
        "                         retrieve_limit: int=5,\n",
        "                         chunk_size: int=256,\n",
        "                         hnsw_config_keys: List[str]=['maxConnections', 'efConstruction', 'ef'],\n",
        "                         display_properties: List[str]=['doc_id', 'guest', 'content'],\n",
        "                         dir_outpath: str='./eval_results',\n",
        "                         include_miss_info: bool=False,\n",
        "                         user_def_params: Dict[str,Any]=None\n",
        "                         ) -> Dict[str, str|int|float]:\n",
        "    '''\n",
        "    Given a dataset and a retriever evaluate the performance of the retriever. Returns a dict of kw and vector\n",
        "    hit rates and mrr scores. If inlude_miss_info is True, will also return a list of kw and vector responses\n",
        "    and their associated queries that did not return a hit, for deeper analysis. Text file with results output\n",
        "    is automatically saved in the dir_outpath directory.\n",
        "\n",
        "    Args:\n",
        "    -----\n",
        "    dataset: EmbeddingQAFinetuneDataset\n",
        "        Dataset to be used for evaluation\n",
        "    class_name: str\n",
        "        Name of Class on Weaviate host to be used for retrieval\n",
        "    retriever: WeaviateClient\n",
        "        WeaviateClient object to be used for retrieval\n",
        "    retrieve_limit: int=5\n",
        "        Number of documents to retrieve from Weaviate host\n",
        "    chunk_size: int=256\n",
        "        Number of tokens used to chunk text. This value is purely for results\n",
        "        recording purposes and does not affect results.\n",
        "    display_properties: List[str]=['doc_id', 'content']\n",
        "        List of properties to be returned from Weaviate host for display in response\n",
        "    dir_outpath: str='./eval_results'\n",
        "        Directory path for saving results.  Directory will be created if it does not\n",
        "        already exist.\n",
        "    include_miss_info: bool=False\n",
        "        Option to include queries and their associated kw and vector response values\n",
        "        for queries that are \"total misses\"\n",
        "    user_def_params : dict=None\n",
        "        Option for user to pass in a dictionary of user-defined parameters and their values.\n",
        "    '''\n",
        "\n",
        "    results_dict = {'n':retrieve_limit,\n",
        "                    'Retriever': retriever.model_name_or_path,\n",
        "                    'chunk_size': chunk_size,\n",
        "                    'kw_hit_rate': 0,\n",
        "                    'kw_mrr': 0,\n",
        "                    'vector_hit_rate': 0,\n",
        "                    'vector_mrr': 0,\n",
        "                    'total_misses': 0,\n",
        "                    'total_questions':0\n",
        "                    }\n",
        "    #add hnsw configs and user defined params (if any)\n",
        "    results_dict = add_params(client, class_name, results_dict, user_def_params, hnsw_config_keys)\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    miss_info = []\n",
        "    for query_id, q in tqdm(dataset.queries.items(), 'Queries'):\n",
        "        results_dict['total_questions'] += 1\n",
        "        hit = False\n",
        "        #make Keyword, Vector, and Hybrid calls to Weaviate host\n",
        "        try:\n",
        "            kw_response = retriever.keyword_search(request=q, class_name=class_name, limit=retrieve_limit, display_properties=display_properties)\n",
        "            vector_response = retriever.vector_search(request=q, class_name=class_name, limit=retrieve_limit, display_properties=display_properties)\n",
        "\n",
        "            #collect doc_ids and position of doc_ids to check for document matches\n",
        "            kw_doc_ids = {result['doc_id']:i for i, result in enumerate(kw_response, 1)}\n",
        "            vector_doc_ids = {result['doc_id']:i for i, result in enumerate(vector_response, 1)}\n",
        "\n",
        "            #extract doc_id for scoring purposes\n",
        "            doc_id = dataset.relevant_docs[query_id][0]\n",
        "\n",
        "            #increment hit_rate counters and mrr scores\n",
        "            if doc_id in kw_doc_ids:\n",
        "                results_dict['kw_hit_rate'] += 1\n",
        "                results_dict['kw_mrr'] += 1/kw_doc_ids[doc_id]\n",
        "                hit = True\n",
        "            if doc_id in vector_doc_ids:\n",
        "                results_dict['vector_hit_rate'] += 1\n",
        "                results_dict['vector_mrr'] += 1/vector_doc_ids[doc_id]\n",
        "                hit = True\n",
        "\n",
        "            # if no hits, let's capture that\n",
        "            if not hit:\n",
        "                results_dict['total_misses'] += 1\n",
        "                miss_info.append({'query': q, 'kw_response': kw_response, 'vector_response': vector_response})\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "\n",
        "\n",
        "    #use raw counts to calculate final scores\n",
        "    calc_hit_rate_scores(results_dict)\n",
        "    calc_mrr_scores(results_dict)\n",
        "\n",
        "    end = time.perf_counter() - start\n",
        "    print(f'Total Processing Time: {round(end/60, 2)} minutes')\n",
        "    record_results(results_dict, chunk_size, dir_outpath=dir_outpath, as_text=True)\n",
        "\n",
        "    if include_miss_info:\n",
        "        return results_dict, miss_info\n",
        "    return results_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cd5ed71-d150-4312-9d41-0b43ae43bd72",
      "metadata": {
        "id": "1cd5ed71-d150-4312-9d41-0b43ae43bd72"
      },
      "source": [
        "### Run evaluation over golden dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d42568cd-d0e3-4640-8865-37b6dff80307",
      "metadata": {
        "id": "d42568cd-d0e3-4640-8865-37b6dff80307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33,
          "referenced_widgets": [
            "d804886e14674e44800ce6d157cbaed4",
            "df96fa3dac1c47919b3c5f4091055557",
            "ea956188bf3b464c8fbf58b7ca055ceb",
            "028c141aa4d646389edcb30b90e10d1e",
            "195e68f5faa64146bfb16937fa8edc73",
            "954ec7f6893043658bb5e9a0152170a3",
            "f6315984dc294f9c981484189d4888ff",
            "83a15b44bfc2414dace545134200b1cf",
            "8fea68ee791b4b2a9f582ec1be9e52ca",
            "bdee2d6814ff4553889d1a1b58e474d5",
            "82f78046d3ab4d2ead43dbc594a0df12"
          ]
        },
        "outputId": "ca23c33d-10bd-4bd0-a44f-8a6d4cf839e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Queries:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d804886e14674e44800ce6d157cbaed4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Total Processing Time: \u001b[1;36m0.42\u001b[0m minutes\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total Processing Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.42</span> minutes\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#################\n",
        "##  START CODE ##\n",
        "#################\n",
        "results = retrieval_evaluation(golden_dataset,class_name,client)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Uqtc98qY7qy",
        "outputId": "c1e1849c-06ff-4c58-f968-4716f7c1c1d9"
      },
      "id": "5Uqtc98qY7qy",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n': 5,\n",
              " 'Retriever': 'sentence-transformers/all-MiniLM-L6-v2',\n",
              " 'chunk_size': 256,\n",
              " 'kw_hit_rate': 0.72,\n",
              " 'kw_mrr': 0.59,\n",
              " 'vector_hit_rate': 0.37,\n",
              " 'vector_mrr': 0.29,\n",
              " 'total_misses': 25,\n",
              " 'total_questions': 100,\n",
              " 'maxConnections': 32,\n",
              " 'efConstruction': 128,\n",
              " 'ef': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d20ebe-be43-43fc-b43c-1657ae9569f9",
      "metadata": {
        "id": "50d20ebe-be43-43fc-b43c-1657ae9569f9"
      },
      "source": [
        "# Conclusion\n",
        "***\n",
        "\n",
        "We now have a way of measuring the performance of our system.  This will allow you to make tweaks/changes to the system and then be able to objectively tell whether or not the tweak/change improved or degraded its performance.  Here are a few things to consider going forward:  \n",
        "\n",
        "- Keep in mind what the ulitmate goal of the system is that you are building.  For this course, we are trying to retrieve the most relevant documents as possible that will effectively address a user query, assuming the information is found within the corpus.  This means that we don't need pages and pages of relevant results, we actually only need the top 3-5, just enough to allow our Reader (the OpenAI LLM) to answer the user query.  This is an important point to be thinking about as you are making changes to the retrieval system.\n",
        "- Feel free to set the `include_miss_info` param to `True`.  Doing so will return a list of both the keyword and vector responses that did not contain the relevant `doc_id` (a \"total_miss\" means the `doc_id` was not present in either the `kw_doc_ids` or the `vector_doc_ids`).  Take a look at the style of the queries being asked and compare them with the returned responses.  Why are those responses being returned?  Are they close to the intent of the query?\n",
        "- Last but not least, you are now free to make changes to your system to improve the `hit_rate` and `mrr` scores.  If it were me, I'd start with switching out to a more performant [embedding model](https://huggingface.co/spaces/mteb/leaderboard).  There will be more opportunities to pick up some low hanging fruit, but we'll have to wait until the following week when hybrid search and Rerankers are introduced.  Whatever you do though, don't change params for the `SentenceSplitter` that you use for chunking the corpus.  Due to the way the golden dataset is derived, it's unfortunately dependent on those original `SentenceSplitter` settings remaining the same across evaluations. That is, of course, unless you want to build out your own golden dataset...."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f49f46-a414-4cce-9e33-812be531e46d",
      "metadata": {
        "id": "a7f49f46-a414-4cce-9e33-812be531e46d"
      },
      "source": [
        "# **OPTIONAL but encouraged... --> Fine-Tuning an Embedding Model\n",
        "***\n",
        "#### This exercise won't cost you anything except some time...\n",
        "\n",
        "#### It is recommended to run this specific section either locally on your machine or on Google Colab. As a proxy, it will take less than 10 minutes to run in a Macbook Air M1.\n",
        "\n",
        "Aside from switching out your emebdding model to improve your retrieval results, you could also try fine tuning your embedding model (or better yet, switch out your model and then fine tune the new one...👊).  For the longest time, the problem with fine-tuning sentence embedding models was the lack of access to high quality training data.  Generative LLMs can save you days/weeks of time, depending on how large of a dataset you want to create, by automating the process of generating high quality query/context pairs.  In this section we'll go over the step-by-step process of fine-tuning our `all-MiniLM-L6-v2` embedding model from a pre-generated training dataset consisting of only 300 question-context pairs, and then comparing it's retrieval results to our baseline retrieval scores.  I highly encourage trying this method out, I saw a 10+ point jump in `vector_hit_rate` after fine-tuning the baseline model.\n",
        "\n",
        "### Fine-tune Walkthrough\n",
        "\n",
        "1. Get baseline retrieval scores (vector Hit Rate, MRR, and total misses) using out-of-the-box baseline model.  You won't know objectively if fine-tuning had any effect if you don't measure the baseline results first.  I know this goes without saying it, but practitioners sometimes want to jump straight into model improvement without first considering their starting point.\n",
        "2. Collect a training and validation dataset.  This step has already been completed for you, courtesy of `gpt-3.5-turbo`.  LlamaIndex has a great out-of-the-box solution for generating query/context embedding pairs, but it isn't exactly plug and play, so I had to rewrite the function to achieve comptability for our course.  The training dataset consists of queries generated by the LLM that can be answered from the associated context (text chunk).  These pairs were generated using a prompt specifically written for the Impact Theory corpus so the training and validation data (for the most part) are high quality and contextually relevant.\n",
        "3. Instantiate a `SentenceTransformersFinetuneEngine` Class written by LlamaIndex which does a great job of abstracting away most of the details invovled in fine-tuning a Sentence Transformer model.\n",
        "4. Fit the model and set a path where the new model will reside.  I creaed a `models/` directory in the course repo, and included the directory in the `.gitignore` file so that models aren't being pushed with every commit.\n",
        "5. Create a new dataset (as you learned in Notebook 1) but this time create the embeddings using the new fine-tuned model.\n",
        "6. Create a new index on Weaviate using the new dataset you just created.\n",
        "7. Run the `retrieval_evaluation` function again, but this time instantiate your Weaviate client with the new fine-tuned model, but hold all other parameters constant (i.e. don't change any other parameter from the baseline run).\n",
        "8. Compare the fine-tuned retrieval results to the baseline results 🥳"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65048057-c7b1-4838-88d1-8717f2541fc6",
      "metadata": {
        "id": "65048057-c7b1-4838-88d1-8717f2541fc6"
      },
      "source": [
        "### Import Training + Valid datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73235f35-982c-446b-bc2c-7decc6cb7145",
      "metadata": {
        "id": "73235f35-982c-446b-bc2c-7decc6cb7145"
      },
      "outputs": [],
      "source": [
        "training_path = './data/training_data_300.json'\n",
        "valid_path = './data/validation_data_100.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c71fbb-95f4-40bd-a76c-f136629e6acf",
      "metadata": {
        "id": "62c71fbb-95f4-40bd-a76c-f136629e6acf",
        "outputId": "ed32069c-54d7-48e6-c2bb-b5b76ede9246"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># Training Samples: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>\n",
              "# Validation Samples: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "# Training Samples: \u001b[1;36m300\u001b[0m\n",
              "# Validation Samples: \u001b[1;36m100\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "training_set = EmbeddingQAFinetuneDataset.from_json(training_path)\n",
        "valid_set = EmbeddingQAFinetuneDataset.from_json(valid_path)\n",
        "num_training_examples = len(training_set.queries)\n",
        "num_valid_examples = len(valid_set.queries)\n",
        "print(f'# Training Samples: {num_training_examples}\\n# Validation Samples: {num_valid_examples}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7407014d-ace1-4ab3-b62f-92dd0fad0246",
      "metadata": {
        "id": "7407014d-ace1-4ab3-b62f-92dd0fad0246"
      },
      "source": [
        "### Wrangle Model output path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b9c2eb1-f487-44be-894e-b5bf105c702d",
      "metadata": {
        "id": "7b9c2eb1-f487-44be-894e-b5bf105c702d"
      },
      "outputs": [],
      "source": [
        "#always a good idea to name your fine-tuned so that you can easily identify it,\n",
        "#especially if you plan on doing multiple training runs with different params\n",
        "#also probably a good idea to include the # of training samples you are using in the name\n",
        "\n",
        "model_id = client.model_name_or_path\n",
        "model_ext = model_id.split('/')[1]\n",
        "models_dir = './models'\n",
        "if not os.path.exists('./models'):\n",
        "    os.makedirs('./models')\n",
        "else:\n",
        "    print(f'{models_dir} already exists')\n",
        "ft_model_name = f'finetuned-{model_ext}-{num_training_examples}'\n",
        "model_outpath = os.path.join(models_dir, ft_model_name)\n",
        "\n",
        "print(f'Model ID: {model_id}')\n",
        "print(f'Model Outpath: {model_outpath}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce4f8049-27d8-49fd-be18-360d3d8c6acb",
      "metadata": {
        "id": "ce4f8049-27d8-49fd-be18-360d3d8c6acb"
      },
      "source": [
        "### Instantiate your Fine-tune engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f118bf22-9c0d-47ad-aa83-e7f61ce07a7e",
      "metadata": {
        "id": "f118bf22-9c0d-47ad-aa83-e7f61ce07a7e"
      },
      "outputs": [],
      "source": [
        "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
        "\n",
        "finetune_engine = SentenceTransformersFinetuneEngine(\n",
        "    training_set,\n",
        "    batch_size=32,\n",
        "    model_id=model_id,\n",
        "    model_output_path=model_outpath,\n",
        "    val_dataset=valid_set,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2aaa840-de9e-4e17-8a9d-7c412cd873bb",
      "metadata": {
        "id": "d2aaa840-de9e-4e17-8a9d-7c412cd873bb"
      },
      "source": [
        "### Fit the embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5068ae60-3a73-4170-9310-4c74f9cd9563",
      "metadata": {
        "id": "5068ae60-3a73-4170-9310-4c74f9cd9563"
      },
      "outputs": [],
      "source": [
        "# finetune_engine.finetune()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08e8aad-5a91-4c25-ab85-f1af821b250c",
      "metadata": {
        "id": "e08e8aad-5a91-4c25-ab85-f1af821b250c"
      },
      "source": [
        "The `finetune` method will automatically generate the model directory using the `model_output_path` that you define.  Inside the directory will be a copy of the model itself (`pytorch_model.bin`) along with all the other files it needs.  Also in that folder, assuming you provide a `val_dataset` will be an evaluation report in the `eval` directory.  The evaluation report contains several IR metrics that may or may not be useful to you, but it does allow you to compare score improvements with each training epoch.  The new fine-tuned model is loaded through the `SentenceTransformer` class just like any other HuggingFace repo model."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "openai",
      "language": "python",
      "name": "openai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d804886e14674e44800ce6d157cbaed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df96fa3dac1c47919b3c5f4091055557",
              "IPY_MODEL_ea956188bf3b464c8fbf58b7ca055ceb",
              "IPY_MODEL_028c141aa4d646389edcb30b90e10d1e"
            ],
            "layout": "IPY_MODEL_195e68f5faa64146bfb16937fa8edc73",
            "tabbable": null,
            "tooltip": null
          }
        },
        "df96fa3dac1c47919b3c5f4091055557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_954ec7f6893043658bb5e9a0152170a3",
            "placeholder": "​",
            "style": "IPY_MODEL_f6315984dc294f9c981484189d4888ff",
            "tabbable": null,
            "tooltip": null,
            "value": "Queries: 100%"
          }
        },
        "ea956188bf3b464c8fbf58b7ca055ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_83a15b44bfc2414dace545134200b1cf",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fea68ee791b4b2a9f582ec1be9e52ca",
            "tabbable": null,
            "tooltip": null,
            "value": 100
          }
        },
        "028c141aa4d646389edcb30b90e10d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bdee2d6814ff4553889d1a1b58e474d5",
            "placeholder": "​",
            "style": "IPY_MODEL_82f78046d3ab4d2ead43dbc594a0df12",
            "tabbable": null,
            "tooltip": null,
            "value": " 100/100 [00:25&lt;00:00,  4.01it/s]"
          }
        },
        "195e68f5faa64146bfb16937fa8edc73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "954ec7f6893043658bb5e9a0152170a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6315984dc294f9c981484189d4888ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "83a15b44bfc2414dace545134200b1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fea68ee791b4b2a9f582ec1be9e52ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdee2d6814ff4553889d1a1b58e474d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f78046d3ab4d2ead43dbc594a0df12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}